# 2022-03-16
# Machine Learning
(Dobbiamo pensare al progetto... subito...)
## TOC
- Sistemi di raccomandazione
- Polinomial Regression
- Valutazione della regressione
- Overfitting
## Formalizzazione di un modello di perceptron
Modello: $h_\theta=\theta_0 x_0+\theta_1 x_1+\ldots+\theta_n x_n \implies \theta^Tx$
Funzione costo: $C(\theta)=\frac{1}{2m}\sum\limits_i(h_\theta(x^{(i)})-y^{(i)})^2$
Algoritmo di learning: ***Discesa del Gradiente*** (Di tipo *batch*) (anche chiamato ***Stocastic Gradient Descend***)
$\theta_j\leftarrow\theta_j-\alpha(\frac{\delta C(\theta)}{\delta\theta_j})\forall j$
con $\alpha>0$

> L'algoritmo di learning ripete $k$ volte $\theta_j\leftarrow\theta_j-\alpha(\frac{\delta C(\theta)}{\delta\theta_j})\forall j$

> In base alla $\alpha$ che scegliamo il grafico che descrive l'andamento della ***Discesa del Gradiente*** può prendere varie forme:
>
> - inizia a scendere, ma poi risale: $\alpha$ troppo elevato
> - molto lento a scendere: $\alpha$ troppo basso
> - se mantiene una buona velocità di discesa e non risale, andando quindi a convergenza: $\alpha$ buona

> Con questo algoritmo e questa funzione di costo è possibile analizzare anche funzioni più complesse di $h_\theta$ e potrebbero avere vari minimi locali, in genere un minimo locale è buono tanto quanto gli altri(ci possono essere eccezioni)

Convergenza: $e^{-\text{qualcosa che non leggo}}$
Calcolo della derivata della funzione costo rispetto a $\theta_j$:
$\frac{\delta C(\theta)}{\delta\theta_j}=\frac{1}{m}\sum\limits_i(h_\theta(x^{(i)})-y^{(i)})x^{(i)}_j$

Siamo in un dominio normalizzato:
$x^{(i)}_j\in[0,1]$

(spiega cose strane sulle dimensioni di case ed il loro numero per spiegare... boh credo le dimensionalità o la normalizzazione... si normalizzazione sembra)
Per riuscire a far convergere l'algoritmo della ***Discesa del Gradiente*** efficentemente bisogna rimappare gli input in modo adeguato
(ha fatto vedere un'esempio di come la discesa del gradiente di input rimappati creano un bolla circolare invece che ovale e diventa più veloce)

```ad-def
title:Algoritmo di learning *Batch*
Rende possibile eseguire l'algoritmo su di un campionamento $m_s$ sotto insieme del training set
```

```ad-eg
title:$t$-esimo istante della discesa del gradiente
$\theta_{0,t} = 1,\theta_{1,t} = 2$
$h_\theta(x^{(i)})=\theta_0+\theta_1x_1$
calcolare i valori di $\theta_0$ e $\theta_1$ all'istante t+2
Training Set

| x_0 | x_1 | y |
| --- | --- | - |
| 1   | 1   | 0 |
| 1   | 0   | 2 |

$\theta_{0,t+1}\leftarrow\theta_{0,t}-\frac{1}{2}\sum\limits_{i=1}^{2}(\theta_{0,t}+\theta_{1,t}x^{(i)}_1-y^{(i)})x_0$
$\theta_{1,t+1}\leftarrow\theta_{1,t}-\frac{1}{2}\sum\limits_{i=1}^{2}(\theta_{0,t}+\theta_{1,t}x^{(i)}_1-y^{(i)})x_1$
Ripetere pr ottenere $\theta_{0,t+2}$ e $\theta_{1,t+2}$

(Esercizio: completarlo a casa... non lo farò mai ma sh)
```

(Un tizio dietro di me dice una cosa interessante)
Se consideriamo la derivata della funzione di costo possiamo renderci conto che sta risalendo(la funzione) perchè cambia segno(la derivata), ma non è facilmente applicabile e forse ti da più problemi che altro...

````ad-eg
Assegnare il giusto valore di $\alpha$ al giusto grafico (ora come cazzo faccio i grafici? ahahah...)
![[Esercizio20210316.png]]

1. $\alpha=1$
2. $\alpha=0.1$
3. $\alpha=0.01$

```ad-solution
collapse:true
1. C
2. A
3. B
```
(ce l'ho fatta...)
````

(ora c'è na tabella enorme...)

| Film | GMF | MM    | DD  | AB  |
| ---- | --- | ----- | --- | --- |
| F1   | 5   | 5     | 0   | 0   |
| F2   | 5   | ?=4.5 | ?=0 | 0   |
| F3   | ?=5 | 4     | 0   | ?=0 |
| F4   | 0   | 0     | 5   | 4   |
| F5   | 0   | 0     | 5   | ?=4 |

Features:
Romantico: F1,F2,F3
Azione: F4,F5

(In base alle features si può cercare di indovinare che valori avrebbero i ***?***)

Se formalizzassimo un algoritmo di raccomandazione avremmo due nuove colonne che identificherebbero le features ed un'ulteriore per il bias:

| Film | GMF | MM | DD | AB | Romantico | Azione | Bias |
| ---- | --- | -- | -- | -- | --------- | ------ | ---- |
| F1   | 5   | 5  | 0  | 0  | 0.9       | 0      | 1    |
| F2   | 5   | ?  | ?  | 0  | 0.8       | 0.1    | 1    |
| F3   | ?   | 4  | 0  | ?  | 0.99      | 0      | 1    |
| F4   | 0   | 0  | 5  | 4  | 0         | 0.7    | 1    |
| F5   | 0   | 0  | 5  | ?  | 0.1       | 0.9    | 1    |

GMF: $\theta^{(GMF)}$
MM($\theta^{(MM)}$) | DD($\theta^{(DD)}$) | AB($\theta^{(AB)}$) | Romantico($x_1$) | Azione($x_2$) | Bias($x_0$) |

(mi sto confondendooooo... ok ha risolto le mie confusioni)
$h_\theta(\theta^{(GMF)}) = \theta^{(GMF)}_0+\theta^{(GMF)}_1x_1+\theta^{(GMF)}_2x_2$
e.g.
$\theta^{(GMF)}_0+\theta^{(GMF)}_10.9+\theta^{(GMF)}_20=5$

(si confonde anche il prof!)

```ad-def
title:Termini
$i$: Riga

$j$: Colonna

$X^{(i)}$: Insieme delle feature ed il bias
> e.g.
> $X^{(3)}=[x^{(3)}_0,x^{(3)}_1,x^{(3)}_2] = [1,0.9,0]$

$y^{(i)}_j$: Cella della tabella
> e.g.
> $y^{(3)}_2 = 4$

$\theta^{(j)}$: I pesi da trovare con ***learning***
```

(non vedo che scrive...)
$\min\limits_{\theta^{(j)}}(\frac{1}{2m}\sum\limits_{i:r(i,j)=1}(\theta^{(j)T}x^{(i)}-y^{(i)}_j)^2)$
la $m$ sarà una costante scalare basata sul numero di elementi e non avrà alcun effetto nell'ottimizzazione della formula

$r(i,j)$ non ho capito bene se è un metodo che restituisce **se** la casella ha valore o **qual è** il valore(penso ***qual è***)

$\min\limits_{\theta^{(1)},\theta^{(2)},\ldots,\theta^{(nu)}}(\sum\limits_{j=1}^{nu}(\frac{1}{2m}\sum\limits_{i:r(i,j)=1}(\theta^{(j)T}x^{(i)}-y^{(i)}_j)^2))$
dove $nu$ è il numero di utenti

(Facciamo un passo avanti)
### Funzione Kernel $\phi(X^{(i)})$
$\phi(X^{(i)}) = \bar{X}^{(i)}$
$(x_1,x_2)\to_{\phi}(x_1^2,\sqrt{2}x_1x_2,x_2^2)$

(sta facendo vedere come se le feature sono tutte concentrate in un posto e attorno a loro ci sono le altre feature)
![[dimostrazione.1 20210316.png]]

> In questo caso non è possibile dividerle con una linea nel piano($\mathscr{R}^2$), per cui ci spostiamo nello spazio($\mathscr{R}^3$) dove sarà possibile dividerli  da un piano

```ad-def Overfitting
L'overfitting ha a che fare con modelli che sono capaci di avere errore quasi nullo nel **training set**, ma poi non sono applicabili nel **caso generico**
```

(THE END...nope)
(TO BE CONTINUED$\rightarrow$)
