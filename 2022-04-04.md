# 2022-04-04
# Machine Learning
## Stocastic gradient decents
Usa un mini batch $p<<m$
Ogni epoca controlliamo $\lfloor\frac{m}{p}\rfloor$ mini batch

---

Variazione del learning rate $\alpha$:

- Time-based: $\alpha_{t}=\alpha_{0}\cdot \frac{1}{1+kt}$
- Step-decay: $\alpha_{t+1}=\alpha_{t}\cdot \frac{1}{2^{e}}$

!def Adagard
Aggiornamenti con learn rating più grandi per i laori sparsi e piccoli, per quelli non sparsi
def!

!def Adam
Utilizza un learning rate per ognuno dei parametri
def!

---

IL momentum è un parametro $\beta$ che identifica il peso del risultato $z$ nella formula della discesa del gradiente
$z^{\text{new}}\leftarrow \beta z^{\text{old}} + \frac{\delta J(\theta)}{\delta\theta}$

---

Alcune metriche utili

- Matrice di confusione
- Accuracy
- F1
  - Precision
  - Recall
- ROC curve

Matrice di confusione
> Fare attenzione alle dimensioni (Reale, Predizione).
> In questo caso sono le righe *Reali* e le colonne *Predizioni*

> La proporzione dei reali è importante

|   | 1 | 0 |
| - | - | - |
| 1 | a | c |
| 0 | d | b |

- TP(Correttamente Positivo): $\frac{a}{a+c}$
- TN(Correttamente Negativo): $\frac{b}{b+d}$
- FP(Scorrettamente Positivo): $\frac{d}{b+d}$
- FN(Scorrettamente Negativo): $\frac{c}{a+c}$
- Accuracy: $\frac{a+b}{a+b+c+d}$
- Precision: $\frac{a}{a+d}$
- Recall (=TP): $\frac{a}{a+c}$
- ROC Curve: $(\vec{\text{Recall}},O,\vec{\text{Precision}})$
  In base ad una *threasold* si può dare importanza alla *Recall* o alla *Precision*
- 