# 2022-04-04
# Machine Learning
## Stocastic gradient decents
Usa un mini batch $p<<m$ 
Ogni epoca controlliamo $\lfloor\frac{m}{p}\rfloor$ mini batch

---

Variazione del learning rate $\alpha$: 
- Time-based: $\alpha_{t}=\alpha_{0}\cdot \frac{1}{1+kt}$
- Step-decay: $\alpha_{t+1}=\alpha_{t}\cdot \frac{1}{2^{e}}$

!def Adagard
Aggiornamenti con learn rating piÃ¹ grandi per i laori sparsi e piccoli, per quelli non sparsi
def!

!def Adam
Utilizza un learning rate per ognuno dei parametri
def!

